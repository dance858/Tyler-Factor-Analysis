{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import pdb \n",
    "from DOA_utils import (generate_ula_data_nonuniform, RootMUSIC1D,\n",
    "                       non_uniform_Gaussian_CRB, nonuniform_MVT_CRB)\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from estimators.N_estimators import sample_mean_and_cov_complex, Gaussian_FA_via_EM_complex\n",
    "from estimators.Tyler_FA_CCP_complex import Tyler_FA_via_CCP_complex\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from matplotlib import pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "seed = 43\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters for the experiment\n",
    "snr = 5\n",
    "theta_rad = np.array([0, 5, 10, 15]) * np.pi / 180\n",
    "num_of_sources, power_source = len(theta_rad), 1\n",
    "P = power_source * np.eye(num_of_sources)\n",
    "wavelength = 1\n",
    "wavelength_factor = 2\n",
    "d = wavelength / wavelength_factor\n",
    "num_of_sensors = 15\n",
    "noise_variances = np.random.rand(num_of_sensors)\n",
    "scaling = np.sum(1/noise_variances) / (snr * num_of_sensors / power_source)\n",
    "noise_variances *= scaling \n",
    "all_num_of_samples = [50, 75, 100, 125, 150, 175, 200]\n",
    "MC_runs = 100\n",
    "all_errors_Tyler_FA_N = np.zeros((len(all_num_of_samples), MC_runs))\n",
    "all_errors_S_N = np.zeros((len(all_num_of_samples), MC_runs))\n",
    "all_errors_G_FA_N = np.zeros((len(all_num_of_samples), MC_runs))\n",
    "all_errors_Tyler_FA_T = np.zeros((len(all_num_of_samples), MC_runs))\n",
    "all_errors_S_T = np.zeros((len(all_num_of_samples), MC_runs))\n",
    "all_errors_G_FA_T = np.zeros((len(all_num_of_samples), MC_runs))\n",
    "degrees_of_freedom = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RootMusicEstimator = RootMUSIC1D(wavelength)\n",
    "max_iter_CCP = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that will process each signal distribution\n",
    "def process_signal_distribution(signal_distribution):\n",
    "    results = {\n",
    "        \"Tyler_FA\": np.zeros((len(all_num_of_samples), MC_runs)),\n",
    "        \"G_FA\": np.zeros((len(all_num_of_samples), MC_runs)),\n",
    "        \"S\": np.zeros((len(all_num_of_samples), MC_runs)),\n",
    "    }\n",
    "    \n",
    "    for ii in range(len(all_num_of_samples)):\n",
    "        num_of_samples = all_num_of_samples[ii]\n",
    "        #print(f\"Simulating num_of_samples = {num_of_samples} for {signal_distribution}\")\n",
    "        \n",
    "        for run in range(MC_runs):\n",
    "            if run % 5 == 0:\n",
    "                print(\"run: \", run)\n",
    "            \n",
    "            [Y, true_cov, A_true] = generate_ula_data_nonuniform(\n",
    "                power_source, noise_variances, d, num_of_sensors, num_of_sources,\n",
    "                num_of_samples, wavelength, theta_rad, degrees_of_freedom, signal_distribution\n",
    "            )\n",
    "            \n",
    "            X = Y - np.mean(Y, axis=1, keepdims=True)\n",
    "\n",
    "            # Compute covariance estimates\n",
    "            S_EM = sample_mean_and_cov_complex(X)[1]\n",
    "            F_G, d_G = Gaussian_FA_via_EM_complex(S_EM, num_of_sources, 100)\n",
    "            \n",
    "            G_Tyler, e_Tyler, all_QN_iter, H = Tyler_FA_via_CCP_complex(\n",
    "                X, num_of_sources, max_iter_CCP, DCP=True\n",
    "            )\n",
    "            cov_Tyler = LA.inv(np.diag(e_Tyler) - G_Tyler @ G_Tyler.conj().T)\n",
    "            FFH_Tyler = cov_Tyler - np.diag(1/e_Tyler) \n",
    "\n",
    "            # Compute DOAs\n",
    "            doa_F_Tyler = np.flip(-RootMusicEstimator.estimate(FFH_Tyler, num_of_sources, d)[1]._locations)\n",
    "            doa_F_G = np.flip(-RootMusicEstimator.estimate(F_G @ F_G.conj().T, num_of_sources, d)[1]._locations)\n",
    "            doa_S = np.flip(-RootMusicEstimator.estimate(S_EM, num_of_sources, d)[1]._locations)\n",
    "\n",
    "            Tyler_error = LA.norm(theta_rad - doa_F_Tyler)**2\n",
    "            G_FA_error = LA.norm(theta_rad - doa_F_G)**2\n",
    "            S_error = LA.norm(theta_rad - doa_S)**2\n",
    "\n",
    "            # Store errors based on signal distribution\n",
    "            if signal_distribution == \"N\":\n",
    "                results[\"Tyler_FA\"][ii, run] = Tyler_error\n",
    "                results[\"G_FA\"][ii, run] = G_FA_error\n",
    "                results[\"S\"][ii, run] = S_error\n",
    "            else:\n",
    "                results[\"Tyler_FA\"][ii, run] = Tyler_error\n",
    "                results[\"G_FA\"][ii, run] = G_FA_error\n",
    "                results[\"S\"][ii, run] = S_error\n",
    "                \n",
    "    return signal_distribution, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating num_of_samples = 50 for NSimulating num_of_samples = 50 for T\n",
      "\n",
      "run: run:   00\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating num_of_samples = 75 for T\n",
      "run:  0\n",
      "Simulating num_of_samples = 75 for N\n",
      "run:  0\n",
      "Simulating num_of_samples = 100 for T\n",
      "run:  0\n",
      "Simulating num_of_samples = 100 for N\n",
      "run:  0\n",
      "Simulating num_of_samples = 125 for T\n",
      "run:  0\n",
      "Simulating num_of_samples = 125 for N\n",
      "run:  0\n",
      "Simulating num_of_samples = 150 for T\n",
      "run:  0\n",
      "Simulating num_of_samples = 150 for N\n",
      "run:  0\n",
      "Simulating num_of_samples = 175 for T\n",
      "run:  0\n",
      "Simulating num_of_samples = 175 for N\n",
      "run:  0\n",
      "Simulating num_of_samples = 200 for T\n",
      "run:  0\n",
      "Simulating num_of_samples = 200 for N\n",
      "run:  0\n"
     ]
    }
   ],
   "source": [
    "# Run the parallelized code\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool(processes=2) as pool:  # Set the number of processes\n",
    "        # Run process_signal_distribution in parallel for each signal distribution\n",
    "        results = pool.map(process_signal_distribution, ['N', 'T'])\n",
    "\n",
    "    # Combine results for both signal distributions\n",
    "    for signal_distribution, result in results:\n",
    "        if signal_distribution == \"N\":\n",
    "            all_errors_Tyler_FA_N = result[\"Tyler_FA\"]\n",
    "            all_errors_G_FA_N = result[\"G_FA\"]\n",
    "            all_errors_S_N = result[\"S\"]\n",
    "        else:\n",
    "            all_errors_Tyler_FA_T = result[\"Tyler_FA\"]\n",
    "            all_errors_G_FA_T = result[\"G_FA\"]\n",
    "            all_errors_S_T = result[\"S\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute CRBs\n",
    "CRB_N = []\n",
    "CRB_T = []\n",
    "for samples in all_num_of_samples:\n",
    "    CRB_N.append(np.trace(non_uniform_Gaussian_CRB(P, theta_rad, noise_variances,\n",
    "                                    num_of_sensors, 1 / wavelength_factor, samples)))\n",
    "    CRB_T.append(np.trace(nonuniform_MVT_CRB(P, theta_rad, np.diag(noise_variances), \n",
    "                                             num_of_sensors, samples, \n",
    "                                             1 / wavelength_factor, \n",
    "                                             degrees_of_freedom)[0]))\n",
    "CRB_N = np.array(CRB_N)\n",
    "CRB_T = np.array(CRB_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_Tyler_N = np.mean(all_errors_Tyler_FA_N, axis=1)\n",
    "MSE_G_FA_N = np.mean(all_errors_G_FA_N, axis=1)\n",
    "MSE_S_N = np.mean(all_errors_S_N, axis=1)\n",
    "MSE_Tyler_T = np.mean(all_errors_Tyler_FA_T, axis=1)\n",
    "MSE_G_FA_T = np.mean(all_errors_G_FA_T, axis=1)\n",
    "MSE_S_T = np.mean(all_errors_S_T, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "for distribution in ['N', 'T']:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    if distribution == \"N\":\n",
    "        MSE_Tyler = MSE_Tyler_N\n",
    "        MSE_G_FA = MSE_G_FA_N \n",
    "        MSE_S = MSE_S_N \n",
    "        CRB = CRB_N \n",
    "    else:\n",
    "        MSE_Tyler = MSE_Tyler_T\n",
    "        MSE_G_FA = MSE_G_FA_T\n",
    "        MSE_S = MSE_S_T\n",
    "        CRB = CRB_T\n",
    "\n",
    "    # Plot MSEs with markers and error bars\n",
    "    ax.semilogy(all_num_of_samples, MSE_Tyler, marker='o', linestyle='-', linewidth=4, markersize=12,  label='Tyler-FA')\n",
    "    ax.semilogy(all_num_of_samples, MSE_G_FA, marker='s', linestyle='--', linewidth=4, markersize=12, label='G-FA')\n",
    "    ax.semilogy(all_num_of_samples, MSE_S, marker='d', linestyle='-.', linewidth=4, markersize=12, label='SC')\n",
    "    ax.semilogy(all_num_of_samples, CRB, linestyle='--', linewidth=4, label='CRB')\n",
    "    ax.set_xlabel('number of samples', fontsize=24)\n",
    "    ax.set_ylabel('MSE (radians)', fontsize=24)\n",
    "    ax.set_xlim(45, 205)\n",
    "    ax.set_ylim(1e-5, 5*1e-1)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    if distribution == \"N\":\n",
    "        location = 'upper right'\n",
    "    else:\n",
    "        location = 'right' \n",
    "    ax.legend(loc=location, fontsize=16)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Ensure tight layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f'DOA_distribution={distribution}_CCP_iter={max_iter_CCP}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f\"DOA_data_CCP_iter={max_iter_CCP}.npz\", \n",
    "         all_errors_Tyler_FA_N=all_errors_Tyler_FA_N, all_errors_S_N=all_errors_S_N, \n",
    "         all_errors_G_FA_N = all_errors_G_FA_N, \n",
    "         all_errors_Tyler_FA_T=all_errors_Tyler_FA_T, all_errors_S_T=all_errors_S_T, \n",
    "         all_errors_G_FA_T = all_errors_G_FA_T, \n",
    "         all_num_of_samples=all_num_of_samples,\n",
    "         theta_rad=theta_rad, noise_variances=noise_variances, \n",
    "         num_of_sensors=num_of_sensors, snr=snr, degrees_of_freedom=degrees_of_freedom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
